

\chapter{Methodology} \label{ch:methodology}
This chapter defines the methodology used to develop the framework for testing the \gls{db}. The chapter is divided into several sections, each focusing on a specific aspect of the methodology. The first section introduces the development process as a whole, including a detailed plan with measurable milestones to ensure a systematic and robust development. The  second section discusses the first milestone which describes the test setup, including \gls{cs}, \gls{sw} algorithm, and \gls{hil} system. The third section provides an overview of the \gls{ds} used for training and testing the model, including \gls{dc}, annotation, and preprocessing techniques. Furthermore it discusses the \gls{od} algorithm and its pipeline, including the selection of a pre-trained model and the training process. Finally, the fourth section covers integration techniques, including algorithm integration with \gls{cs} and synchronization with \gls{hil} system.

\section{Introduction}
The methodology used in this project is devided over 3 main milestones. The first milestone focuses on the test setup, which includes the selection of a suitable \gls{cs}, light control, and the integration of a \gls{hil} system. The goal of this milestone is to develope a complete closed loop setup that is ready to integrate the model and run the detection process in the test environment. The second milestone involves the preparation of a \gls{ds} in an automated way using photoshop files, peform annotations, preprocessing and augmantation to increase model generalization. Furthermore, the  milestone includes the training of the chosen \gls{od} model using the prepared \gls{ds} and testing its performance on camera pictures from the \gls{cs}. The third milestone focuses on the integration of the trained \gls{od} model with the \gls{sw} that synchronizes with the \gls{hil} system.

\section{Test Setup}
The test setup is a crucial part of the project as it provides the environment in which the \gls{db} will be tested and evaluated. The setup includes the selection of a suitable \gls{cs}, light control, and the integration of a \gls{hil} system. The goal of this milestone is to develop a complete closed loop setup that is ready to integrate the model and run the detection process in the test environment. The following sections provide an overview of the test setup, including the \gls{cs}, light control, and \gls{hil} integration.

\subsection{Light Control}
To ensures that the \gls{cs} captures images under a controlled optimum lighting conditions, a light control system is an essential part of the test setup. This is important for the performance of the \gls{od} model, as variations in lighting can significantly affect the quality of the detection model. The light control system should be capable of providing adjustable and uniform illumination across the entire \gls{fov} of the camera. Additionally, it should prevent any external light sources from interfering with the captured images, this is important to ensure that no glare or reflections are present in the images, which can lead to false detections or misclassifications.

KTM uses a light control system that consists of a box with alluminum frame and black walls to prevent any external light or light reflections. The box is equipped with a set of LED lights that can be adjusted to provide the desired level of illumination. The lights are positioned to ensure that the entire \gls{fov} of the camera is evenly illuminated, and they can be controlled remotely to adjust the brightness and color temperature as needed. This allows for complete control over the lighting conditions during the testing process, ensuring that the images captured by the camera are of high quality and suitable for the \gls{od} model. Figure \ref{LightControl} shows the light control system used in the test setup.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.6\textwidth]{Figures/Light_Control_Box.jpg}
    \caption{Light control system used in the test setup.}
    \label{LightControl}
\end{figure}

The box provides a mounting structure for the \gls{cs} to ensure that the \gls{cs} is positioned correctly and securely during the testing process. It also includes a mounting structure for the the \gls{db} to ensure that the distance between the \gls{cs} and the \gls{db} is consistent. Additionally, a cable inlet is provided to allow for the connection of the \gls{cs} and the \gls{db} without compromising the light control system.

Insert an image of the light control system with the camera and \gls{db} mounted inside the box.

\subsection{Camera System}
The \gls{cs} is an important component of the test setup as it captures images of the \gls{db} for testing and evaluation. It should be capable of capturing high-resolution images with a wide \gls{fov} to ensure that all relevant objects are included in the captured frames. Since a light control system is used, the \gls{cs} does not need to be highly sensitive to light variations and since the \gls{db} is a static object, the camera does not need to be highly sensitive to motion blur.

Due to the availability of a \gls{cs} at KTM , it was recommended to use the available \gls{cs}. The \gls{cs} used in this project is a high-resolution camera provided by Cognex, a company specialized in \gls{cs}s for industrial usecases. The camera is capable of capturing images at a resolution of up to 12 mega pixels (4096 x 3000) pixels, which is sufficient for the \gls{od} model to detect and classify objects accurately \cite{Cognex_Camera}. The camera provides a varienty of communication interfaces, including Ethernet, which allows for easy integration with the \gls{sw} to capture and retrieve images smoothly through \gls{telnet} and \gls{ftp} protocols. Figure \ref{Cognex_Camera} shows the \gls{cs} used in the test setup.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.5\textwidth]{Figures/In-Sight 9000 in hand.jpg}
    \caption{Cognex \gls{cs} used in the test setup \cite{Cognex_Camera}.}
    \label{Cognex_Camera}
\end{figure}

The camera is mounted inside the light control box to ensure that it is positioned correctly and securely during the testing process. The mounting structure allows for easy adjustment of the camera's position and angle to ensure that the entire \gls{db} is captured in the images. Additionally, the camera is connected to a computer via Ethernet, which allows for easy access to the captured images and integration with the \gls{sw}. Figure \ref{Camera_Mounting} shows the \gls{cs} mounted inside the light control box.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=0.6\textwidth]{Figures/Camera_Mounting.jpg}
    \caption{\gls{cs} mounted inside the light control box.}
    \label{Camera_Mounting}
\end{figure}

\subsection{Hardware In The Loop System}
The \gls{hil} is considered as the backbone of this test setup as it simulate the real-world environment in which the \gls{db} will operate. It allows for the testing and evaluation of the \gls{db} in a controlled environment. In this project, a Vector-provided \gls{hil} system is used, it is featuring a toolchain that includes Vector CANoe and VTest Studio, which are used to to create test scenarios and send the required CAN messages to the \gls{db} to trigger a specific frame.

Moreover, the toolchain uses .NET framework which allows for easy integration with the \gls{sw} algorithm to send requests from the \gls{hil} to the \gls{sw} to capture an image and process using the \gls{od} model then compare it with the expected results and a response is sent back to the \gls{hil} system. Based on this evaluation, the \gls{hil} system automatically logs the outcome of the test case as either passed or failed.

The communication between the \gls{hil} system and the \gls{sw} algorithm is done through a TCP/IP connection, which allows for real-time communication and synchronization between the two systems. This allows the \gls{sw} algorithm to capture images from the \gls{cs} and process them using the \gls{od} model, while the \gls{hil} system sends requests and receives responses in real-time.


\section{Dataset}
A \gls{ds} could be defined as a structured collection of data that could be used for analysis, modeling and decision making. \gls{ds} exist in various formats, including numerical values, text, images and videos. In the scope of \gls{dl} and \gls{od}, a \gls{ds} is essential for training, validating and testing models. Moreover, the performance of an \gls{od} model highly depends on the quality and volume of the data available. Therefore, \gls{ds} collection and preparation is normally considered as the backbone of a high performance \gls{od} model. In \gls{od}, \gls{ds} primarily consist of images or video frames annotated with bounding boxes and labeled by classes to define the locations and categories of objects. For general \gls{od} tasks, one can use existing \gls{ds}s such as COCO, PASCAL VOC, and ImageNet which contain thousands of standardized and annotated images and video frames across multiple classes which are released over the last years. On the other hand, for solving highly specific tasks, a custom \gls{ds} may be required to train the model, making this step very complicated and time consuming step. However, using transfer learning and pre-trained models have reduced the need to collect thousands of images, as training with just a few hundred samples can result in a very satisfactory performance \cite{IBM_Transfer_Learning}. Additionally, modern annotation \gls{sw} available and different augmentation techniques help automate the process and scale up the \gls{ds} volume to deliver the best results. In this section, \gls{ds} collection, annotation and preprocessing techniques are discussed to collect high quality and volume \gls{ds} \cite{oD_Review}.

\subsection{Data Collection}
As stated earlier, \gls{od} algorithms heavily depend on the quality and volume of the data provided. This makes the \gls{dc} process a very important factor for the performance of the model. To reach good results, \gls{dc} process should follow a systematic approach consisting of multiple steps.

\subsubsection{Understanding Data Requirements}
The \gls{dc} process depends highly on the type of task to be performed. These tasks could be image segmentation, image classification, \gls{od}, facial recognition and pattern detection. Each one of these tasks require different type of \gls{ds} and understanding the task and clearly define the objectives are the fist steps in building the \gls{ds} \cite{AIMultiple_Computer_Vision_Training_Data}. In this study, as mentioned earlier, the focus is on \gls{od}, which involves image classification and localization.

Once the task is defined, the next step is to determine the appropriate training images and object categories. For example, if the model is designed to detect pedestrians, one should not use food images for training \gls{ds}, instead, the \gls{ds} should consist of images or videos of people walking on sidewalks or while crossing the road \cite{AIMultiple_Computer_Vision_Training_Data}. Similarly, in \gls{db} \gls{od}, it is essential to use relevant images or frames that include all assets during the training phase to reach the best results. Figure \ref{KTM_DB_Unlabelled} provides a sample of relevant data used for this project. 

Last requirement to consider is the environment in which the \gls{od} model will operate. One should consider such an aspect during the \gls{dc} process to ensure that the \gls{od} model will operate as expected in the real world. These factors include lighting conditions background clutter and object occlusion, which can highly result in a completely different performance than the one produced from the validation and testing steps \cite{AIMultiple_Computer_Vision_Training_Data}. Later in this chapter, a discussion will take place on how to minimize environmental effects and the setup used in this project to enhance model robustness.

\begin{figure}[!htb] 
    \centering
    \includegraphics[width=0.3\textwidth]{Figures/Portrait_MainScreenPSD.JPG}
    \caption{KTM \gls{db} frame that includes some of the required assets like speed, air temperature and fuel range.}
    \label{KTM_DB_Unlabelled}
\end{figure}

\subsubsection{\gls{dc} Method Selection}
In \gls{od} projects, the methods of collecting the data are directly impacting not only the quality and quantity of the \gls{ds} but also the overall project cost and development time. Different \gls{dc} methods can be selected to ensure project efficiency:

\begin{itemize}
    \item \textbf{Crowed Sourcing}: This method is effective when a large and diverse image or video \gls{ds} within a limited time frame needs to be collected. Contributors are reached through online platforms to collect labeled and unlabeled data. This method benefits from scalability, cost and time effectiveness and diversity of the \gls{ds}. However, it suffers from problems like lack of quality consistency and requires effective quality control mechanisms to ensure the quality \cite{AIMultiple_Computer_Vision_Training_Data}.
    \item \textbf{Private Collection}: Private \gls{dc} refers to gathering data internally within a controlled environment. This method is used when highly customized \gls{ds} is required to ensure hat the data is tailored to specific project needs. The advantages of this method include higher data quality, better control over labeling accuracy and compliance with privacy or security requirements. However, it is relatively expensive and time-consuming \cite{AIMultiple_Computer_Vision_Training_Data}.
    \item \textbf{Off-The-Shelf \gls{ds}s}: Off-the-shelf \gls{ds} are publicly available, pre-collected \gls{ds} that researchers and developers can use directly for training and evaluation. The main advantages of using off-the-shelf \gls{ds} are that they are cost effective, easy to access and often come with high quality annotations. However, challenge is the limited customization as they may not match the project requirements \cite{AIMultiple_Computer_Vision_Training_Data}.
    \item \textbf{Generative \gls{ai}}: Generative \gls{ai} refers to \gls{ai} models that create synthetic data, including images, text and videos. this data can be used to augment \gls{ds} or generate entirely new training samples. Advantages include the ability to generate diverse and controlled data, reduce the need for real world \gls{dc} and enhance model generalization. However, challenges include the risk of synthetic data not perfectly representing real world conditions and environmental factors and inability to generate highly specific data for a specific product \cite{AIMultiple_Computer_Vision_Training_Data}.
\end{itemize}

Since the data required for this project is highly specific to the KTM \gls{db} and must comply with the privacy and security requirements. Therefore, the private collection method was chosen as the most suitable approach.

\subsubsection{High Quality Data Preparation}
To ensure that the data collected for an \gls{od} project is of high quality, several key factors must be considered. One of the most important factors is data diversity, as it directly impacts the model’s ability to generalize to real-world variations. To enhance model robustness, the \gls{ds} should include diverse objects, frames, positions, and lighting conditions during the \gls{dc} process. Additionally, accurate annotation with labels and bounding boxes is essential for enabling the model to correctly classify and localize objects within an image. A balanced \gls{ds} is also crucial to prevent model bias toward specific classes; therefore, an equal number of images per object class should be maintained. Furthermore, high-resolution and distortion-free images positively impact the model’s performance by ensuring clearer object features and reducing noise in training data.



\subsection{Data Annotation And Labeling}
........
\subsection{Dataset Preprocessing}
.........
\subsection{Augmentation Techniques}
........

\section{Object Detection And Classification Algorithm}
.........
\subsection{Overview Of Object Detection Pipeline}
.........
\subsection{Selection Of the Pretrained Model}
.........
\subsection{Data Preprocessing And Augmentation}
.........
\subsection{Model Fine-Tuning And Training Process}
..................
\subsection{Post-Processing And Object Classification}
.........
\subsection{Model Evaluation Metrics}
.........
\section{Test Setup}
.........
\subsection{Camera System}
.........
\subsection{Light Control And Mounting}
.........
\subsection{Hardware In The Loop System}
.........
\section{Integration Techniques}
.........
\subsection{Algorithm Integration With Camera System}
.........
\subsection{Synchronization With Hardware In The Loop System}
.........
\subsection{Data Flow And Processing Pipeline}
.........
